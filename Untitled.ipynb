{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why doesn't an optical mouse work on a glass t...</td>\n",
       "      <td>or even on some surfaces?</td>\n",
       "      <td>Optical mice use an LED and a camera to rapidl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>What is the best off-road motorcycle trail ?</td>\n",
       "      <td>long-distance trail throughout CA</td>\n",
       "      <td>i hear that the mojave road is amazing!&lt;br /&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What is Trans Fat? How to reduce that?</td>\n",
       "      <td>I heard that tras fat is bad for the body.  Wh...</td>\n",
       "      <td>Trans fats occur in manufactured foods during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>How many planes Fedex has?</td>\n",
       "      <td>I heard that it is the largest airline in the ...</td>\n",
       "      <td>according to the www.fedex.com web site:\\nAir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>In the san francisco bay area, does it make se...</td>\n",
       "      <td>the prices of rent and the price of buying doe...</td>\n",
       "      <td>renting vs buying depends on your goals. &lt;br /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399995</th>\n",
       "      <td>3</td>\n",
       "      <td>do all these ads on tv of yoko etc regarding h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I increased my height 2 feet afterwards so yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399996</th>\n",
       "      <td>7</td>\n",
       "      <td>Ways to sell your video games?</td>\n",
       "      <td>Like if you want to sell your video games how ...</td>\n",
       "      <td>ebay, electronic boutique, babbages or flea ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399997</th>\n",
       "      <td>3</td>\n",
       "      <td>is it normal to have nots in your breast or bo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It can be normal as long as they are not cance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399998</th>\n",
       "      <td>1</td>\n",
       "      <td>Who can speak Hindi??</td>\n",
       "      <td>If you can write it here!!</td>\n",
       "      <td>Main hindi bol sakti hoon.kahiye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399999</th>\n",
       "      <td>5</td>\n",
       "      <td>where can i find websites  were i can have a v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>★★ HELP WITH SEARCHING ★★\\n\\n◙ I used to have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  \\\n",
       "0        5  why doesn't an optical mouse work on a glass t...   \n",
       "1        6       What is the best off-road motorcycle trail ?   \n",
       "2        3             What is Trans Fat? How to reduce that?   \n",
       "3        7                         How many planes Fedex has?   \n",
       "4        7  In the san francisco bay area, does it make se...   \n",
       "...     ..                                                ...   \n",
       "1399995  3  do all these ads on tv of yoko etc regarding h...   \n",
       "1399996  7                     Ways to sell your video games?   \n",
       "1399997  3  is it normal to have nots in your breast or bo...   \n",
       "1399998  1                              Who can speak Hindi??   \n",
       "1399999  5  where can i find websites  were i can have a v...   \n",
       "\n",
       "                                                         2  \\\n",
       "0                                or even on some surfaces?   \n",
       "1                        long-distance trail throughout CA   \n",
       "2        I heard that tras fat is bad for the body.  Wh...   \n",
       "3        I heard that it is the largest airline in the ...   \n",
       "4        the prices of rent and the price of buying doe...   \n",
       "...                                                    ...   \n",
       "1399995                                                NaN   \n",
       "1399996  Like if you want to sell your video games how ...   \n",
       "1399997                                                NaN   \n",
       "1399998                         If you can write it here!!   \n",
       "1399999                                                NaN   \n",
       "\n",
       "                                                         3  \n",
       "0        Optical mice use an LED and a camera to rapidl...  \n",
       "1        i hear that the mojave road is amazing!<br />\\...  \n",
       "2        Trans fats occur in manufactured foods during ...  \n",
       "3        according to the www.fedex.com web site:\\nAir ...  \n",
       "4        renting vs buying depends on your goals. <br /...  \n",
       "...                                                    ...  \n",
       "1399995  I increased my height 2 feet afterwards so yes...  \n",
       "1399996  ebay, electronic boutique, babbages or flea ma...  \n",
       "1399997  It can be normal as long as they are not cance...  \n",
       "1399998                  Main hindi bol sakti hoon.kahiye.  \n",
       "1399999  ★★ HELP WITH SEARCHING ★★\\n\\n◙ I used to have ...  \n",
       "\n",
       "[1400000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('yahoo_answers_csv/train.csv', header=None)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>What makes friendship click?</td>\n",
       "      <td>How does the spark keep going?</td>\n",
       "      <td>good communication is what does it.  Can you m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Why does Zebras have stripes?</td>\n",
       "      <td>What is the purpose or those stripes? Who do t...</td>\n",
       "      <td>this provides camouflage - predator vision is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>What did the itsy bitsy sipder climb up?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>waterspout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the difference between a Bachelors and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One difference between a Bachelors and a Maste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Why do women get PMS?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Premenstrual syndrome (PMS) is a group of symp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>if you could be any fantasy figure, who would ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The invisible man, I'd be straight into the gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>8</td>\n",
       "      <td>Tell me something about life most people don't...</td>\n",
       "      <td>Do you know anything about life, or words of w...</td>\n",
       "      <td>That there is a hell and everyone thinks their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>3</td>\n",
       "      <td>Why are men always thinking of sex?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's wired in our brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>est ce que DOMENECH est un entraineur: 1: de f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de foot mais pas pour être sélectionneur d'une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>5</td>\n",
       "      <td>No sound or low sound?</td>\n",
       "      <td>I have my volume turned up all the way and hav...</td>\n",
       "      <td>As an old techie, I tend to look at the hardwa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1  \\\n",
       "0      9                       What makes friendship click?   \n",
       "1      2                      Why does Zebras have stripes?   \n",
       "2      4           What did the itsy bitsy sipder climb up?   \n",
       "3      4  What is the difference between a Bachelors and...   \n",
       "4      3                              Why do women get PMS?   \n",
       "...   ..                                                ...   \n",
       "59995  9  if you could be any fantasy figure, who would ...   \n",
       "59996  8  Tell me something about life most people don't...   \n",
       "59997  3                Why are men always thinking of sex?   \n",
       "59998  6  est ce que DOMENECH est un entraineur: 1: de f...   \n",
       "59999  5                             No sound or low sound?   \n",
       "\n",
       "                                                       2  \\\n",
       "0                         How does the spark keep going?   \n",
       "1      What is the purpose or those stripes? Who do t...   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59995                                                NaN   \n",
       "59996  Do you know anything about life, or words of w...   \n",
       "59997                                                NaN   \n",
       "59998                                                NaN   \n",
       "59999  I have my volume turned up all the way and hav...   \n",
       "\n",
       "                                                       3  \n",
       "0      good communication is what does it.  Can you m...  \n",
       "1      this provides camouflage - predator vision is ...  \n",
       "2                                             waterspout  \n",
       "3      One difference between a Bachelors and a Maste...  \n",
       "4      Premenstrual syndrome (PMS) is a group of symp...  \n",
       "...                                                  ...  \n",
       "59995  The invisible man, I'd be straight into the gi...  \n",
       "59996  That there is a hell and everyone thinks their...  \n",
       "59997                            It's wired in our brain  \n",
       "59998  de foot mais pas pour être sélectionneur d'une...  \n",
       "59999  As an old techie, I tend to look at the hardwa...  \n",
       "\n",
       "[60000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('yahoo_answers_csv/test.csv', header=None)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well.  Everyone has different definition on what \\'beauty\\' is.  I like Lin Qingxia, but I think many girls are prettier than she was. (She is more than 40 years old now). \\\\nIf \"Lin Qingxia\" is the most beautiful woman in the Chinese cinema, the most handsome man in Chinese cinema should be \"Chin Han\" because they always made movies together.\\\\nHowever, A male movie star once was asked his girlfriend in real life or the girlfriend in movie is more beautiful.  He gave a very good answer: \"I think my mother is the most beautiful woman in the world.\"  :)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[8][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwordsList = stopwords.words('english')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "q1_noGrammer = tokenizer.tokenize(train[3].values[0])\n",
    "# q1_word_tokens = word_tokenize(q1_noGrammer)\n",
    "filtered_sentence_q1 = [ps.stem(w) for w in q1_noGrammer if not w.lower() in stop_words]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentcount = 0\n",
    "word_frequency={}\n",
    "for i in filtered_sentence_q1:\n",
    "    if i in word_frequency:\n",
    "        word_frequency[i]+=1   \n",
    "    else:\n",
    "        word_frequency[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwordsList = stopwords.words('english')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train1 = train[[1,3]].dropna()\n",
    "for docnum in range(len(train)):\n",
    "    if(docnum % 100000 == 0):\n",
    "        print(docnum)\n",
    "    q1_noGrammer = tokenizer.tokenize(train1[3].values[docnum])\n",
    "    # q1_word_tokens = word_tokenize(q1_noGrammer)\n",
    "    filtered_sentence_q1 = [ps.stem(w) for w in q1_noGrammer if not w.lower() in stop_words]\n",
    "    word_frequency={}\n",
    "    for i in filtered_sentence_q1:\n",
    "        if i in word_frequency:\n",
    "            word_frequency[i]+=1   \n",
    "        else:\n",
    "            word_frequency[i]=1\n",
    "    df = pd.DataFrame()\n",
    "    df['word'] = word_frequency.keys()\n",
    "    df['document'] = f'doc{docnum}'\n",
    "    df['weight'] = word_frequency.values()\n",
    "    if not os.path.isfile('answers_to_graph.csv'):\n",
    "        df.to_csv('answers_to_graph.csv', header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "        df.to_csv('answers_to_graph.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[3].values[docnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>document</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>optic</td>\n",
       "      <td>doc0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mice</td>\n",
       "      <td>doc0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>use</td>\n",
       "      <td>doc0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>led</td>\n",
       "      <td>doc0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>camera</td>\n",
       "      <td>doc0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36207157</th>\n",
       "      <td>126</td>\n",
       "      <td>dropdown</td>\n",
       "      <td>doc1375420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36207158</th>\n",
       "      <td>127</td>\n",
       "      <td>menu</td>\n",
       "      <td>doc1375420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36207159</th>\n",
       "      <td>128</td>\n",
       "      <td>type</td>\n",
       "      <td>doc1375420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36207160</th>\n",
       "      <td>129</td>\n",
       "      <td>keyword</td>\n",
       "      <td>doc1375420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36207161</th>\n",
       "      <td>130</td>\n",
       "      <td>searchalot</td>\n",
       "      <td>doc1375420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36207162 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0        word    document  weight\n",
       "0                  0       optic        doc0       1\n",
       "1                  1        mice        doc0       1\n",
       "2                  2         use        doc0       2\n",
       "3                  3         led        doc0       1\n",
       "4                  4      camera        doc0       2\n",
       "...              ...         ...         ...     ...\n",
       "36207157         126    dropdown  doc1375420       1\n",
       "36207158         127        menu  doc1375420       1\n",
       "36207159         128        type  doc1375420       1\n",
       "36207160         129     keyword  doc1375420       1\n",
       "36207161         130  searchalot  doc1375420       1\n",
       "\n",
       "[36207162 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('answers_to_graph.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('answers_to_graph.csv')\n",
    "df = df[['word','document','weight']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_frequency={}\n",
    "docs = df['document']\n",
    "for i in docs:\n",
    "    if i in doc_frequency:\n",
    "        doc_frequency[i]+=1   \n",
    "    else:\n",
    "        doc_frequency[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_doc_frequency = {}\n",
    "max_wdf = 0\n",
    "min_wdf = 9999999999\n",
    "for doc in doc_frequency:\n",
    "    wdf = doc_frequency[doc]\n",
    "    if(max_wdf < wdf):\n",
    "        max_wdf = wdf\n",
    "    if(wdf > 10):\n",
    "        filter_doc_frequency[doc] = wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filter_doc_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency={}\n",
    "words = df['word']\n",
    "for i in words:\n",
    "    if i in word_frequency:\n",
    "        word_frequency[i]+=1   \n",
    "    else:\n",
    "        word_frequency[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word_frequency = {}\n",
    "max_idf = 0\n",
    "for words in word_frequency:\n",
    "    idf = word_frequency[words]\n",
    "    if(max_idf < idf):\n",
    "        max_idf = idf\n",
    "    if(idf > 40) & (idf < 50000):\n",
    "        filter_word_frequency[words] = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filter_word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word_frequency.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filter_word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "docs = []\n",
    "weights = []\n",
    "word_keys = filter_word_frequency.keys()\n",
    "doc_keys = filter_doc_frequency.keys()\n",
    "for ind in range(len(df)):\n",
    "    slc = df.iloc[ind]\n",
    "    if((slc['word'] in word_keys) & (slc['document'] in doc_keys)):\n",
    "        words.append(slc['word'])\n",
    "        docs.append(slc['document'])\n",
    "        weights.append(slc['weight'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"word\": words, \"document\": docs, \"weight\": weights}\n",
    "filtered_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = filtered_df[:1000000]['word'].unique()\n",
    "temp_list2 = filtered_df[:1000000]['document'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_list) + len(temp_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a temporary list to store the string labels\n",
    "temp_list = filtered_df[:1000000]['word'].unique()\n",
    "temp_list2 = filtered_df[:1000000]['document'].unique()\n",
    "\n",
    "# dictionary that maps integer to its string value \n",
    "id_to_node = {}\n",
    "node_to_id = {}\n",
    "# list to store integer labels \n",
    "int_labels = []\n",
    "\n",
    "for i in range(60441):\n",
    "    if(i < 25328):\n",
    "        id_to_node[i] = temp_list[i]\n",
    "        node_to_id[temp_list[i]] = i\n",
    "        int_labels.append(i)\n",
    "    else:\n",
    "        id_to_node[i] = temp_list2[i-25393]\n",
    "        node_to_id[temp_list2[i-25393]] = i\n",
    "        int_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('id_to_node.pkl', 'wb') as f:\n",
    "    pickle.dump(id_to_node, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"train\"\n",
    "pastdoc = \"doc0\"\n",
    "finalString = \"\"\n",
    "currentString = \"\"\n",
    "subgraph_ids = []\n",
    "for ind in range(1000000):\n",
    "    row = filtered_df.iloc[ind]\n",
    "    word = row['word']\n",
    "    doc = row['document']\n",
    "    weight = row['weight']\n",
    "    if(ind == 700000):\n",
    "        dataset = \"val\"\n",
    "    if(ind == 900000):\n",
    "        dataset = 'test'\n",
    "    if(pastdoc != doc):\n",
    "        subids = \"-\".join(subgraph_ids)\n",
    "        currentString = f\"{subids}\\t{node_to_id[pastdoc]}\\t{dataset}\\n\"\n",
    "        if(pastdoc == 'doc0'):\n",
    "            file1 = open(\"C:/Users/jncwi/OneDrive/School/CS637/SubGNN/yahoo/subgraphs.pth\", \"w\")\n",
    "            file1.write(currentString)\n",
    "            file1.close()\n",
    "        else:\n",
    "            file1 = open(\"C:/Users/jncwi/OneDrive/School/CS637/SubGNN/yahoo/subgraphs.pth\", \"a\")\n",
    "            string_encode = currentString.encode(\"ascii\", \"ignore\")\n",
    "            string_decode = string_encode.decode()\n",
    "            file1.write(string_decode)\n",
    "            file1.close()\n",
    "#         finalString = f\"{finalString}{currentString}\"\n",
    "#         currentString = f\"{word}\\t{doc}\\t{dataset}\\n\"\n",
    "        pastdoc = doc\n",
    "        subgraph_ids = []\n",
    "    else:\n",
    "        subgraph_ids.append(f\"{node_to_id[word]}\")\n",
    "#         currentString = f\"{word}-\".join(currentString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_idd = filtered_df[:1000000]\n",
    "def trans_id2(nid):\n",
    "    return node_to_id[nid]\n",
    "filtered_df_idd['word'] = filtered_df_idd[['word']].applymap(trans_id2)\n",
    "filtered_df_idd['document'] = filtered_df_idd[['document']].applymap(trans_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.from_pandas_edgelist(filtered_df_idd, 'word', 'document', ['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, \"C:/Users/jncwi/OneDrive/School/CS637/SubGNN/yahoo/edge_list.txt\", data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HouseDataset(T.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, tmp_x, tmp_y, m_rows=None):\n",
    "        self.x_data = T.tensor(tmp_x, \\\n",
    "                               dtype=T.float32).to(device)\n",
    "        self.y_data = T.tensor(tmp_y.reshape(-1, 1), \\\n",
    "                               dtype=T.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        preds = self.x_data[idx, :]  # or just [idx]\n",
    "        price = self.y_data[idx, :]\n",
    "        return (preds, price)  # tuple of two matrices\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = T.nn.Linear(100, 100)  # 8-(10-10)-1\n",
    "        self.hid2 = T.nn.Linear(100, 100)\n",
    "        self.oupt = T.nn.Linear(100, 1)\n",
    "\n",
    "        T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "        T.nn.init.zeros_(self.hid1.bias)\n",
    "        T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "        T.nn.init.zeros_(self.hid2.bias)\n",
    "        T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "        T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = T.relu(self.hid1(x))\n",
    "        z = T.relu(self.hid2(z))\n",
    "        z = T.sigmoid(self.oupt(z))  # no activation\n",
    "        return z\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy(model, ds, pct):\n",
    "    # assumes model.eval()\n",
    "    # percent correct within pct of true house price\n",
    "    n_correct = 0;\n",
    "    n_wrong = 0\n",
    "\n",
    "    for i in range(len(ds)):\n",
    "        (X, Y) = ds[i]  # (predictors, target)\n",
    "        with T.no_grad():\n",
    "            oupt = model(X)  # computed price\n",
    "\n",
    "        abs_delta = np.abs(oupt.item() - Y.item())\n",
    "        max_allow = np.abs(pct * Y.item())\n",
    "        if abs_delta < max_allow:\n",
    "            n_correct += 1\n",
    "        else:\n",
    "            n_wrong += 1\n",
    "\n",
    "    acc = (n_correct * 1.0) / (n_correct + n_wrong)\n",
    "    return acc\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def accuracy_quick(model, dataset, pct):\n",
    "    # assumes model.eval()\n",
    "    n = len(dataset)\n",
    "    X = dataset[0:n][0]  # all predictor values\n",
    "    Y = dataset[0:n][1]  # all target prices\n",
    "    with T.no_grad():\n",
    "        oupt = model(X)  # all computed prices\n",
    "\n",
    "    max_deltas = T.abs(pct * Y)  # max allowable deltas\n",
    "    abs_deltas = T.abs(oupt - Y)  # actual differences\n",
    "\n",
    "    results = abs_deltas < max_deltas  # [[True, False, . .]]\n",
    "    acc = T.sum(results, dim=0).item() / n  # dim not needed\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from botdet.data.data_utils import h5group_to_dict\n",
    "from scipy.sparse import csr_matrix,lil_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import vstack,hstack\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "class loader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.countID=0\n",
    "        self.G={}\n",
    "        self.co={}\n",
    "        self.revco={}\n",
    "    \n",
    "    def nodeID(self,x):\n",
    "        if x not in self.co:\n",
    "            self.co[x]=self.countID\n",
    "            self.countID=self.countID+1\n",
    "            self.revco[self.co[x]]=x\n",
    "        return self.co[x]\n",
    "    \n",
    "    def read(self,file):\n",
    "        x=pd.read_csv(file,sep=' ',header=None).values\n",
    "        for a in range(x.shape[0]):\n",
    "            i=self.nodeID(x[a,0])\n",
    "            j=self.nodeID(x[a,1])\n",
    "            self.addEdge((i,j))\n",
    "        self.fixG()\n",
    "        \n",
    "    def storeEmb(self,file,data):\n",
    "        file1 = open(file, 'w') \n",
    "        for a in range(data.shape[0]):\n",
    "            s=''+str(int(self.revco[a]))\n",
    "            for b in range(data.shape[1]):\n",
    "                s+=' '+str(data[a,b])\n",
    "            file1.write(s+\"\\n\")\n",
    "        file1.close()\n",
    "            \n",
    "    \n",
    "    def fixG(self):\n",
    "        for g in range(len(self.G)):\n",
    "            self.G[g]=np.array([x for x in self.G[g]])\n",
    "\n",
    "    def addEdge(self,s):\n",
    "        (l1,l2)=s\n",
    "        if l1 not in self.G:\n",
    "            self.G[l1]=set()\n",
    "        if l2 not in self.G:\n",
    "            self.G[l2]=set()\n",
    "        self.G[l1].add(l2)\n",
    "        self.G[l2].add(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#g[i][0] nodes outgoing from node i \n",
    "class inferentialSirGNKmean:\n",
    "    \n",
    "    def __init__(self,n,n1,depth,ngr):\n",
    "        self.levelsProcessor=[]\n",
    "        self.n=n\n",
    "        self.depth=depth\n",
    "        self.n1=n1\n",
    "        self.pca= IncrementalPCA(n_components=n1)\n",
    "        self.scaler=StandardScaler()\n",
    "        self.ngr=ngr\n",
    "        self.G={}\n",
    "        \n",
    "    \n",
    "    def transformInternal(self,G):\n",
    "        nv=len(G) \n",
    "        degree=np.array([[G[x][0].shape[0]] for x in range(nv)])\n",
    "        emb1=degree*np.ones((nv,self.n))\n",
    "        degree=np.array([[G[x][1].shape[0]] for x in range(nv)])\n",
    "        emb2=degree*np.ones((nv,self.n))\n",
    "        emb=np.hstack([emb1,emb2])\n",
    "        for reg,gmm in self.levelsProcessor:\n",
    "            emb1=reg.fit_transform(emb)\n",
    "            val=gmm.transform(emb1)\n",
    "            M=val.max(axis=1)\n",
    "            m=val.min(axis=1)\n",
    "            subx=(M.reshape(nv,1)-val)/(M-m).reshape(nv,1)\n",
    "            #print(subx.shape)\n",
    "            su=subx.sum(axis=1)\n",
    "            #print(su.shape)\n",
    "            subx=subx/su.reshape(nv,1)\n",
    "            #print(np.max(np.sum(subx,axis=1)))\n",
    "            hh=[subx[G[i][0],:].sum(axis=0) if len(G[i][0])>0 else np.zeros(self.n) for  i in range(nv)]\n",
    "            emb1=np.vstack(hh)\n",
    "            hh=[subx[G[i][1],:].sum(axis=0) if len(G[i][1])>0 else np.zeros(self.n) for  i in range(nv)]\n",
    "            emb2=np.vstack(hh)\n",
    "            emb=np.hstack([emb1,emb2])\n",
    "        #print(emb)\n",
    "        return emb\n",
    "    \n",
    "    def transformFull(self,G):\n",
    "        li=[]\n",
    "        nv=len(G) \n",
    "        degree=np.array([[G[x][0].size] for x in g.nodes])\n",
    "        emb1=degree*np.ones((nv,self.n))\n",
    "        degree=np.array([[G[x][1].shape[0]] for x in g.nodes])\n",
    "        emb2=degree*np.ones((nv,self.n))\n",
    "        emb=np.hstack([emb1,emb2])\n",
    "        li.append(emb)\n",
    "        for reg,gmm in self.levelsProcessor:\n",
    "            emb1=reg.fit_transform(emb)\n",
    "            val=gmm.transform(emb1)\n",
    "            M=val.max(axis=1)\n",
    "            m=val.min(axis=1)\n",
    "            subx=(M.reshape(nv,1)-val)/(M-m).reshape(nv,1)\n",
    "            #print(subx.shape)\n",
    "            su=subx.sum(axis=1)\n",
    "            #print(su.shape)\n",
    "            subx=subx/su.reshape(nv,1)\n",
    "            #print(np.max(np.sum(subx,axis=1)))\n",
    "            hh=[subx[G[i][0],:].astype(int).sum(axis=0) if G[i][0].size>0 else np.zeros(self.n) for  i in g.nodes]\n",
    "            emb1=np.vstack(hh)\n",
    "            hh=[subx[G[i][1],:].astype(int).sum(axis=0) if len(G[i][1])>0 else np.zeros(self.n) for  i in g.nodes]\n",
    "            emb2=np.vstack(hh)\n",
    "            emb=np.hstack([emb1,emb2])\n",
    "            li.append(emb)\n",
    "        return np.hstack(li)\n",
    "    \n",
    "    \n",
    "    def transform(self,G):\n",
    "        h=self.transformFull(G)\n",
    "        return self.pca.transform(self.scaler.transform(h))\n",
    "    \n",
    "    def transform1(self,G):\n",
    "        h=self.transformFull(G)\n",
    "        return self.scaler.transform(h)\n",
    "    \n",
    "    def transform2(self,G):\n",
    "        h=self.transformFull(G)\n",
    "        return self.scaler1.transform(self.pca.transform(self.scaler.transform(h)))\n",
    "    \n",
    "    def transformGraph(self,G):\n",
    "        emb1=self.transform2(G)\n",
    "        nv=len(G) \n",
    "        val=self.gkm.transform(emb1)\n",
    "        M=val.max(axis=1)\n",
    "        m=val.min(axis=1)\n",
    "        subx=(M.reshape(nv,1)-val)/(M-m).reshape(nv,1)\n",
    "        #print(subx.shape)\n",
    "        su=subx.sum(axis=1)\n",
    "        #print(su.shape)\n",
    "        subx=subx/su.reshape(nv,1)\n",
    "        reprr=np.zeros(( self.ngr, self.ngr))\n",
    "        for  i in range(nv):\n",
    "            for j in G[i][0]:\n",
    "                reprr+=subx[i].reshape((self.ngr,1))*subx[j].reshape((1,self.ngr))\n",
    "        return reprr\n",
    "    \n",
    "    def transformGraph1(self,G):\n",
    "        emb1=self.transform2(G)\n",
    "        nv=len(G) \n",
    "        val=self.gkm.predict(emb1)\n",
    "        reprr=np.zeros(( self.ngr, self.ngr))\n",
    "        for  i in range(nv):\n",
    "            for j in G[i][0]:\n",
    "                reprr[val[i],val[j]]+=1\n",
    "        return reprr     \n",
    "                \n",
    "    def edge(self,s):\n",
    "        (a,b)=s\n",
    "        if a>b:\n",
    "            return (b,a)\n",
    "        else:\n",
    "            return (a,b)\n",
    "    \n",
    "    def generateRandomGraph(self):\n",
    "        G1={x:[set(),set()] for x in range(self.nnodes)}\n",
    "        edgepercentage=int(self.nnodes*10*(0.1+0.9*np.random.rand()))\n",
    "        for i in range(edgepercentage):\n",
    "            a=random.randint(0,self.nnodes-1)\n",
    "            b=random.randint(0,self.nnodes-1)\n",
    "            while b in G1[a]:\n",
    "                a=random.randint(0,self.nnodes-1)\n",
    "                b=random.randint(0,self.nnodes-1)\n",
    "            G1[a][0].add(b)\n",
    "            G1[b][1].add(a)   \n",
    "        G1={x:[np.array(list(G1[x][0])),np.array(list(G1[x][1]))] for x in range(self.nnodes)}\n",
    "        return G1\n",
    "    \n",
    "    def fit_scaler(self, epochs):\n",
    "        scaler=StandardScaler()\n",
    "        for i in range(epochs):\n",
    "            G=self.generateRandomGraph()\n",
    "            scaler.partial_fit(self.transformInternal(G))\n",
    "        return scaler\n",
    "    \n",
    "    def fit_scaler1(self, epochs):\n",
    "        scaler=StandardScaler()\n",
    "        for i in range(epochs):\n",
    "            G=self.generateRandomGraph()\n",
    "            scaler.partial_fit(self.transformFull(G))\n",
    "        return scaler\n",
    "    \n",
    "    def fit_scaler2(self, epochs):\n",
    "        scaler=StandardScaler()\n",
    "        for i in range(epochs):\n",
    "            G=self.generateRandomGraph()\n",
    "            scaler.partial_fit(self.transform(G))\n",
    "        return scaler\n",
    "    \n",
    "    def fit_scaler_PCA(self, epochs):\n",
    "        self.scaler=self.fit_scaler1(epochs)\n",
    "        self.pca= IncrementalPCA(n_components=self.n1)\n",
    "        for i in range(epochs):\n",
    "            G=self.generateRandomGraph()\n",
    "            self.pca.partial_fit(self.scaler.transform(self.transformFull(G)))\n",
    "        self.scaler1=self.fit_scaler2(epochs)\n",
    "    \n",
    "    def fit_graph_representation(self,epochs):\n",
    "        gmm= MiniBatchKMeans(n_clusters=self.ngr)\n",
    "        for i in range(epochs):\n",
    "            #print('epochs',i)\n",
    "            G=self.generateRandomGraph()\n",
    "            gmm.partial_fit(self.transform2(G))\n",
    "        return gmm\n",
    "    \n",
    "    def fit_scaler_gmm(self, epochs):\n",
    "        scaler=self.fit_scaler(epochs)\n",
    "        gmm= MiniBatchKMeans(n_clusters=self.n)\n",
    "        for i in range(epochs):\n",
    "            #print('epochs',i)\n",
    "            G=self.generateRandomGraph()\n",
    "            gmm.partial_fit(scaler.transform(self.transformInternal(G)))\n",
    "        return (scaler,gmm)\n",
    "        \n",
    "        \n",
    "    def universalFit(self,nnodes,epochs):\n",
    "        self.levelsProcessor=[]\n",
    "        self.nnodes=nnodes\n",
    "        for i in range(self.depth):\n",
    "            print('depth',i)\n",
    "            self.levelsProcessor.append(self.fit_scaler_gmm(epochs))\n",
    "        self.fit_scaler_PCA(epochs)\n",
    "        self.gkm=self.fit_graph_representation(epochs)\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isirgn1 = pickle.load( open( \"sirgn2.obj\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isirgn1.transformFull(formGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formGraph['doc0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formGraph['mice'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formGraph['mice'][1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(0,767):\n",
    "# # g = nx.from_pandas_edgelist(df, 'word', 'document', ['weight'])\n",
    "# # g = nx.Graph()\n",
    "# # graph_dict = h5group_to_dict(h5py.File('data/botnet/processed/p2p_train.hdf5', 'r')[str(i)])\n",
    "# # g.add_nodes_from(range(df['word']))\n",
    "# # g.add_edges_from(zip(df['word'], df['document']))\n",
    "# formGraph = nx.to_dict_of_lists(g)\n",
    "# # for j in g.nodes:\n",
    "# #     formGraph[j] = [formGraph[j],[]]\n",
    "# # for j in range(0,len(g)):\n",
    "# #     formGraph[df['word'][j]][1].append(df['document'][j])   \n",
    "# for j in g.nodes:\n",
    "# #     print(j)\n",
    "#     formGraph[j] = [np.array(formGraph[j][0]),np.array(formGraph[j])]   \n",
    "sweights = isirgn1.transform(formGraph)\n",
    "#     count = 0\n",
    "#     botnodeIndex = []\n",
    "#     notBotnodeIndex = []\n",
    "#     for y in graph_dict['y']:\n",
    "#         if(y == 1):\n",
    "#             botnodeIndex.append(count)\n",
    "#         else:\n",
    "#             notBotnodeIndex.append(count)\n",
    "#         count = count + 1\n",
    "#     randomBotIndex = random.sample(botnodeIndex,100)\n",
    "#     randomNotBotIndex = random.sample(notBotnodeIndex,100)\n",
    "#     newIndex = randomBotIndex + randomNotBotIndex\n",
    "#     if(i == 0):\n",
    "#         combinedWeights = sweights[newIndex]\n",
    "#         combinedY = graph_dict['y'][newIndex]\n",
    "#     else:\n",
    "#         combinedWeights = np.concatenate((combinedWeights,sweights[newIndex]), axis=0)\n",
    "#         combinedY = np.append(combinedY,graph_dict['y'][newIndex])\n",
    "#     print(i)\n",
    "# pickle.dump(combinedWeights,open( \"p2p_weights.obj\", \"wb\" ) )\n",
    "# pickle.dump(combinedY,open( \"p2p_Y.obj\", \"wb\" ) )\n",
    "# clf = RandomForestClassifier(class_weight=\"balanced\",random_state=0, n_estimators=1000, warm_start=True)\n",
    "# clf.fit(combinedWeights, combinedY)\n",
    "# pickle.dump( clf, open( \"isirgn1_rfc_p2p_fixed_4.obj\", \"wb\" ) )\n",
    "print(sweights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HouseDataset(sweights, combinedY)  # all 200 rows\n",
    "\n",
    "bat_size = 10\n",
    "train_ldr = T.utils.data.DataLoader(train_ds,\n",
    "                                    batch_size=bat_size, shuffle=True)\n",
    "\n",
    "# print(f\"\\nStarting training with saved checkpoints: {i}\")\n",
    "for epoch in range(0, 5):\n",
    "    T.manual_seed(1 + epoch)  # recovery reproducibility\n",
    "    epoch_loss = 0  # for one full epoch\n",
    "\n",
    "    # new random set of graphs and new 10 batch set for each epoch\n",
    "\n",
    "    for (batch_idx, batch) in enumerate(train_ldr):\n",
    "        (X, Y) = batch  # (predictors, targets)\n",
    "        optimizer.zero_grad()  # prepare gradients\n",
    "        oupt = net(X)  # predicted prices\n",
    "        loss_val = loss_func(oupt, Y)  # avg per item in batch\n",
    "        epoch_loss += loss_val.item()  # accumulate avgs\n",
    "        loss_val.backward()  # compute gradients\n",
    "        optimizer.step()  # update wts\n",
    "\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(\"epoch = %4d   loss = %0.4f\" % \\\n",
    "              (epoch, epoch_loss))\n",
    "\n",
    "        # save checkpoint\n",
    "        dt = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "        fn = \".\\\\Log\\\\\" + str(dt) + str(\"-\") + \\\n",
    "             str(epoch) + \"_checkpoint.pt\"\n",
    "\n",
    "        info_dict = {\n",
    "            'epoch': epoch,\n",
    "            'net_state': net.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict()\n",
    "        }\n",
    "        T.save(info_dict, fn)\n",
    "ch = 1\n",
    "print(\"\\nSaving trained model state\")\n",
    "fn = \".\\\\Models\\\\textGNN.pth\"\n",
    "T.save(net.state_dict(), fn)\n",
    "\n",
    "print(\"Done \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-12.0.1\\bin\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-12.0.1\\bin\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-12.0.1\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-12.0.1\\\\bin\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\std.py:706: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = \"./index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./index\n",
    "indexer = pt.TRECCollectionIndexer(index_path, blocks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# !rm -rf ./pd_index\n",
    "pd_indexer = pt.DFIndexer(\"C:\\\\Users\\\\jncwi\\\\OneDrive\\\\School\\\\CS637\\\\textGCN\\\\pd_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index()['index'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train[[3]]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['length'] = df2[3].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2.length > 10]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train[[3]].dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index()[[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no metadata\n",
    "# pd_indexer.index(df2[3].astype(str))\n",
    "\n",
    "# Add metadata fields as Pandas.Series objects, with the name of the Series object becoming the name of the meta field.\n",
    "indexref2 = pd_indexer.index(df2[3],df2['index'])\n",
    "# pd_indexer.index(df[\"text\"], df[\"docno\"], df[\"url\"])\n",
    "\n",
    "# Add metadata fields as lists to a keyword arguement\n",
    "# pd_indexer.index(df[\"text\"], docno=[\"1\",\"2\",\"3\"], url=[\"url1\", \"url2\", \"url3\"])\n",
    "\n",
    "# Add the metadata fields with a dictionary\n",
    "# meta_fields={\"docno\":[\"1\",\"2\",\"3\"],\"url\":[\"url1\", \"url2\", \"url3\"]}\n",
    "# pd_indexer.index(df[\"text\"], **meta_fields)\n",
    "\n",
    "# Add the entire dataframe as metadata\n",
    "# pd_indexer.index(df2[3], df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwordsList = stopwords.words('english')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train1 = train[[1,3]].dropna()\n",
    "for docnum in range(len(train)):\n",
    "    if(docnum % 100000 == 0):\n",
    "        print(docnum)\n",
    "    q1_noGrammer = tokenizer.tokenize(train1[3].values[docnum])\n",
    "    # q1_word_tokens = word_tokenize(q1_noGrammer)\n",
    "    filtered_sentence_q1 = [ps.stem(w.lower()) for w in q1_noGrammer if not w.lower() in stop_words]\n",
    "    df = pd.DataFrame()\n",
    "#     print(filtered_sentence_q1)\n",
    "    df['document'] = [f'{docnum}']\n",
    "    df['sentence'] = [' '.join(filtered_sentence_q1)]\n",
    "#     print(df)\n",
    "    if not os.path.isfile('inv_index_df.csv'):\n",
    "        df.to_csv('inv_index_df.csv', header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "        df.to_csv('inv_index_df.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>optic mice use led camera rapidli captur imag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hear mojav road amaz br nsearch onlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>tran fat occur manufactur food process partial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>accord www fedex com web site nair fleet br n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>rent vs buy depend goal br ngener think buy be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018531</th>\n",
       "      <td>0</td>\n",
       "      <td>1018531</td>\n",
       "      <td>believ that tad averag anyway lower exercis al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018532</th>\n",
       "      <td>0</td>\n",
       "      <td>1018532</td>\n",
       "      <td>santa real start man pass toy boy girl town na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018533</th>\n",
       "      <td>0</td>\n",
       "      <td>1018533</td>\n",
       "      <td>yogurt great diet food long choos plain nonfat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018534</th>\n",
       "      <td>0</td>\n",
       "      <td>1018534</td>\n",
       "      <td>yea read profil wikepedia think great think go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018535</th>\n",
       "      <td>0</td>\n",
       "      <td>1018535</td>\n",
       "      <td>danger get wright plan lost 35 pound two month...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018536 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  document  \\\n",
       "0                 0         0   \n",
       "1                 0         1   \n",
       "2                 0         2   \n",
       "3                 0         3   \n",
       "4                 0         4   \n",
       "...             ...       ...   \n",
       "1018531           0   1018531   \n",
       "1018532           0   1018532   \n",
       "1018533           0   1018533   \n",
       "1018534           0   1018534   \n",
       "1018535           0   1018535   \n",
       "\n",
       "                                                  sentence  \n",
       "0        optic mice use led camera rapidli captur imag ...  \n",
       "1                    hear mojav road amaz br nsearch onlin  \n",
       "2        tran fat occur manufactur food process partial...  \n",
       "3        accord www fedex com web site nair fleet br n ...  \n",
       "4        rent vs buy depend goal br ngener think buy be...  \n",
       "...                                                    ...  \n",
       "1018531  believ that tad averag anyway lower exercis al...  \n",
       "1018532  santa real start man pass toy boy girl town na...  \n",
       "1018533  yogurt great diet food long choos plain nonfat...  \n",
       "1018534  yea read profil wikepedia think great think go...  \n",
       "1018535  danger get wright plan lost 35 pound two month...  \n",
       "\n",
       "[1018536 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('inv_index_df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>optic mice use led camera rapidli captur imag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hear mojav road amaz br nsearch onlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tran fat occur manufactur food process partial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>accord www fedex com web site nair fleet br n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rent vs buy depend goal br ngener think buy be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018531</th>\n",
       "      <td>1018531</td>\n",
       "      <td>believ that tad averag anyway lower exercis al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018532</th>\n",
       "      <td>1018532</td>\n",
       "      <td>santa real start man pass toy boy girl town na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018533</th>\n",
       "      <td>1018533</td>\n",
       "      <td>yogurt great diet food long choos plain nonfat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018534</th>\n",
       "      <td>1018534</td>\n",
       "      <td>yea read profil wikepedia think great think go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018535</th>\n",
       "      <td>1018535</td>\n",
       "      <td>danger get wright plan lost 35 pound two month...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         document                                           sentence\n",
       "0               0  optic mice use led camera rapidli captur imag ...\n",
       "1               1              hear mojav road amaz br nsearch onlin\n",
       "2               2  tran fat occur manufactur food process partial...\n",
       "3               3  accord www fedex com web site nair fleet br n ...\n",
       "4               4  rent vs buy depend goal br ngener think buy be...\n",
       "...           ...                                                ...\n",
       "1018531   1018531  believ that tad averag anyway lower exercis al...\n",
       "1018532   1018532  santa real start man pass toy boy girl town na...\n",
       "1018533   1018533  yogurt great diet food long choos plain nonfat...\n",
       "1018534   1018534  yea read profil wikepedia think great think go...\n",
       "1018535   1018535  danger get wright plan lost 35 pound two month...\n",
       "\n",
       "[1018536 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('inv_index_df.csv')\n",
    "df = df[['document','sentence']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"document\": \"docno\", \"sentence\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['docno'] = df['docno'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexref2 = pd_indexer.index(df['text'],df['docno'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\std.py:706: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "PyTerrier 0.8.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-12.0.1\\bin\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-12.0.1\\bin\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-12.0.1\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-12.0.1\\\\bin\\\\'\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "import pandas as pd\n",
    "# !rm -rf ./pd_index\n",
    "pd_indexer = pt.DFIndexer(\"C:\\\\Users\\\\jncwi\\\\OneDrive\\\\School\\\\CS637\\\\textGCN\\\\pd_index\")\n",
    "df = pd.read_csv('inv_index_df.csv')\n",
    "df = df[['document','sentence']]\n",
    "df = df.rename(columns={\"document\": \"docno\", \"sentence\": \"text\"})\n",
    "df['docno'] = df['docno'].astype(str)\n",
    "indexref2 = pd_indexer.index(df['text'],df['docno'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing document 0\n",
      "17:13:13.835 [main] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (4733) - further warnings are suppressed\n",
      "processing document 100000\n",
      "processing document 200000\n",
      "processing document 300000\n",
      "processing document 400000\n",
      "processing document 500000\n",
      "processing document 600000\n",
      "processing document 700000\n",
      "processing document 800000\n",
      "processing document 900000\n",
      "processing document 1000000\n",
      "17:20:13.097 [main] WARN org.terrier.structures.indexing.Indexer - Indexed 454 empty documents\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "os.environ['JDK_HOME'] = \"C:/Program Files/Java/jdk-12.0.1/bin\"\n",
    "os.environ['JAVA_HOME'] = \"C:/Program Files/Java/jdk-12.0.1/bin\"\n",
    "os.environ['PATH'] += ';C:/Program Files/Java/jdk-12.0.1/bin/server/;C:/Program Files/Java/jdk-12.0.1/bin/'\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "import urllib\n",
    "import io\n",
    "def antique_doc_iter():\n",
    "    df = pd.read_csv('inv_index_df.csv')\n",
    "    df = df[['document','sentence']]\n",
    "    df = df.rename(columns={\"document\": \"docno\", \"sentence\": \"text\"})\n",
    "    df['docno'] = df['docno'].astype(str)\n",
    "    df = df.dropna()\n",
    "    for i, line in df.iterrows():\n",
    "        if i % 100000 == 0:\n",
    "            print(f'processing document {i}')\n",
    "        if(len(line['text']) > 10):   \n",
    "            yield {'docno': line['docno'], 'text': line['text']}\n",
    "\n",
    "iter_indexer = pt.IterDictIndexer(\"C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index_3\")\n",
    "\n",
    "doc_iter = antique_doc_iter()\n",
    "indexref3 = iter_indexer.index(doc_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'iter_index_3/data.properties'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-69c69950f939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter_index_3/data.properties'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\datasets.py\u001b[0m in \u001b[0;36mget_dataset\u001b[1;34m(name, **kwargs)\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \u001b[0mds_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'irds:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m         \u001b[0mDATASET_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIRDSDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     \u001b[0mrtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDATASET_MAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1081\u001b[0m     \u001b[0mrtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrtr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'iter_index_3/data.properties'"
     ]
    }
   ],
   "source": [
    "pt.get_dataset('iter_index_3/data.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index_3/data.properties'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexref3.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>419162</td>\n",
       "      <td>445641</td>\n",
       "      <td>0</td>\n",
       "      <td>8.101605</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>773368</td>\n",
       "      <td>822921</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050195</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>722373</td>\n",
       "      <td>768903</td>\n",
       "      <td>2</td>\n",
       "      <td>7.933636</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>336430</td>\n",
       "      <td>357643</td>\n",
       "      <td>3</td>\n",
       "      <td>7.882351</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>117681</td>\n",
       "      <td>124834</td>\n",
       "      <td>4</td>\n",
       "      <td>7.854252</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>904800</td>\n",
       "      <td>961553</td>\n",
       "      <td>995</td>\n",
       "      <td>4.387786</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>929331</td>\n",
       "      <td>987449</td>\n",
       "      <td>996</td>\n",
       "      <td>4.387786</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>11627</td>\n",
       "      <td>12261</td>\n",
       "      <td>997</td>\n",
       "      <td>4.377707</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>120779</td>\n",
       "      <td>128141</td>\n",
       "      <td>998</td>\n",
       "      <td>4.377707</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>131149</td>\n",
       "      <td>139166</td>\n",
       "      <td>999</td>\n",
       "      <td>4.377707</td>\n",
       "      <td>mathematical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid   docid   docno  rank     score         query\n",
       "0     1  419162  445641     0  8.101605  mathematical\n",
       "1     1  773368  822921     1  8.050195  mathematical\n",
       "2     1  722373  768903     2  7.933636  mathematical\n",
       "3     1  336430  357643     3  7.882351  mathematical\n",
       "4     1  117681  124834     4  7.854252  mathematical\n",
       "..   ..     ...     ...   ...       ...           ...\n",
       "995   1  904800  961553   995  4.387786  mathematical\n",
       "996   1  929331  987449   996  4.387786  mathematical\n",
       "997   1   11627   12261   997  4.377707  mathematical\n",
       "998   1  120779  128141   998  4.377707  mathematical\n",
       "999   1  131149  139166   999  4.377707  mathematical\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.BatchRetrieve('C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index_3/data.properties').search(\"mathematical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of('C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index_3/data.properties')\n",
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"vaswani\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteDataset for vaswani, with ['corpus', 'topics', 'qrels', 'index', 'info_url', 'corpus_iter']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani topics to C:\\Users\\jncwi\\.pyterrier\\corpora\\vaswani\\query-text.trec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "query-text.trec: 10.7kiB [00:00, 5.54MiB/s]                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:25:31.676 [main] WARN org.terrier.applications.batchquerying.TRECQuery - trec.encoding is not set; resorting to platform default (windows-1252). Retrieval may be platform dependent. Recommend trec.encoding=UTF-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>measurement of dielectric constant of liquids ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mathematical analysis and design details of wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>use of digital computers in the design of band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>systems of data coding for information transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>use of programs in engineering testing of comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>tunnel diode construction and its electrical c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>electronic density of states at the surface of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>resistivity of metallic thin films related to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>the phenomenon of radiation caused by charged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>high frequency oscillators using transistors t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query\n",
       "0    1  measurement of dielectric constant of liquids ...\n",
       "1    2  mathematical analysis and design details of wa...\n",
       "2    3  use of digital computers in the design of band...\n",
       "3    4    systems of data coding for information transfer\n",
       "4    5  use of programs in engineering testing of comp...\n",
       "..  ..                                                ...\n",
       "88  89  tunnel diode construction and its electrical c...\n",
       "89  90  electronic density of states at the surface of...\n",
       "90  91  resistivity of metallic thin films related to ...\n",
       "91  92  the phenomenon of radiation caused by charged ...\n",
       "92  93  high frequency oscillators using transistors t...\n",
       "\n",
       "[93 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>optic mice use led camera rapidli captur imag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hear mojav road amaz br nsearch onlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tran fat occur manufactur food process partial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>accord www fedex com web site nair fleet br n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rent vs buy depend goal br ngener think buy be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018531</th>\n",
       "      <td>1018531</td>\n",
       "      <td>believ that tad averag anyway lower exercis al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018532</th>\n",
       "      <td>1018532</td>\n",
       "      <td>santa real start man pass toy boy girl town na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018533</th>\n",
       "      <td>1018533</td>\n",
       "      <td>yogurt great diet food long choos plain nonfat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018534</th>\n",
       "      <td>1018534</td>\n",
       "      <td>yea read profil wikepedia think great think go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018535</th>\n",
       "      <td>1018535</td>\n",
       "      <td>danger get wright plan lost 35 pound two month...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid                                              query\n",
       "0              0  optic mice use led camera rapidli captur imag ...\n",
       "1              1              hear mojav road amaz br nsearch onlin\n",
       "2              2  tran fat occur manufactur food process partial...\n",
       "3              3  accord www fedex com web site nair fleet br n ...\n",
       "4              4  rent vs buy depend goal br ngener think buy be...\n",
       "...          ...                                                ...\n",
       "1018531  1018531  believ that tad averag anyway lower exercis al...\n",
       "1018532  1018532  santa real start man pass toy boy girl town na...\n",
       "1018533  1018533  yogurt great diet food long choos plain nonfat...\n",
       "1018534  1018534  yea read profil wikepedia think great think go...\n",
       "1018535  1018535  danger get wright plan lost 35 pound two month...\n",
       "\n",
       "[1013297 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('inv_index_df.csv')\n",
    "df = df[['document','sentence']]\n",
    "df = df.rename(columns={\"document\": \"qid\", \"sentence\": \"query\"})\n",
    "df['qid'] = df['qid'].astype(str)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>docno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013292</th>\n",
       "      <td>1018531</td>\n",
       "      <td>1018531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013293</th>\n",
       "      <td>1018532</td>\n",
       "      <td>1018532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013294</th>\n",
       "      <td>1018533</td>\n",
       "      <td>1018533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013295</th>\n",
       "      <td>1018534</td>\n",
       "      <td>1018534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013296</th>\n",
       "      <td>1018535</td>\n",
       "      <td>1018535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index    docno\n",
       "0              0        0\n",
       "1              1        1\n",
       "2              2        2\n",
       "3              3        3\n",
       "4              4        4\n",
       "...          ...      ...\n",
       "1013292  1018531  1018531\n",
       "1013293  1018532  1018532\n",
       "1013294  1018533  1018533\n",
       "1013295  1018534  1018534\n",
       "1013296  1018535  1018535\n",
       "\n",
       "[1013297 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()[['index','docno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani qrels to C:\\Users\\jncwi\\.pyterrier\\corpora\\vaswani\\qrels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qrels: 24.3kiB [00:00, 3.34MiB/s]                                                                                      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>93</td>\n",
       "      <td>9875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>93</td>\n",
       "      <td>9956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>93</td>\n",
       "      <td>10497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>93</td>\n",
       "      <td>11191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>93</td>\n",
       "      <td>11318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid  docno  label\n",
       "0      1   1239      1\n",
       "1      1   1502      1\n",
       "2      1   4462      1\n",
       "3      1   4569      1\n",
       "4      1   5472      1\n",
       "...   ..    ...    ...\n",
       "2078  93   9875      1\n",
       "2079  93   9956      1\n",
       "2080  93  10497      1\n",
       "2081  93  11191      1\n",
       "2082  93  11318      1\n",
       "\n",
       "[2083 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013292</th>\n",
       "      <td>1018531</td>\n",
       "      <td>1018531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013293</th>\n",
       "      <td>1018532</td>\n",
       "      <td>1018532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013294</th>\n",
       "      <td>1018533</td>\n",
       "      <td>1018533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013295</th>\n",
       "      <td>1018534</td>\n",
       "      <td>1018534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013296</th>\n",
       "      <td>1018535</td>\n",
       "      <td>1018535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           docno      qid\n",
       "0              0        0\n",
       "1              1        1\n",
       "2              2        2\n",
       "3              3        3\n",
       "4              4        4\n",
       "...          ...      ...\n",
       "1013292  1018531  1018531\n",
       "1013293  1018532  1018532\n",
       "1013294  1018533  1018533\n",
       "1013295  1018534  1018534\n",
       "1013296  1018535  1018535\n",
       "\n",
       "[1013297 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()[['index','qid']].rename(columns={\"index\": \"docno\", \"qid\": \"qid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.reset_index()[['index','qid']].rename(columns={\"index\": \"docno\", \"qid\": \"qid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>qid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013292</th>\n",
       "      <td>1018531</td>\n",
       "      <td>1018531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013293</th>\n",
       "      <td>1018532</td>\n",
       "      <td>1018532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013294</th>\n",
       "      <td>1018533</td>\n",
       "      <td>1018533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013295</th>\n",
       "      <td>1018534</td>\n",
       "      <td>1018534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013296</th>\n",
       "      <td>1018535</td>\n",
       "      <td>1018535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013297 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           docno      qid  label\n",
       "0              0        0      1\n",
       "1              1        1      1\n",
       "2              2        2      1\n",
       "3              3        3      1\n",
       "4              4        4      1\n",
       "...          ...      ...    ...\n",
       "1013292  1018531  1018531      1\n",
       "1013293  1018532  1018532      1\n",
       "1013294  1018533  1018533      1\n",
       "1013295  1018534  1018534      1\n",
       "1013296  1018535  1018535      1\n",
       "\n",
       "[1013297 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [tf_idf, bm25],\n",
    "    df,\n",
    "    df2,\n",
    "    eval_metrics=[\"map\", \"recip_rank\"],\n",
    "    names=[\"TF_IDF\", \"BM25\"],\n",
    "    filter_by_topics = True,\n",
    "    filter_by_qrels = True,\n",
    "    save_dir=\"./results\",\n",
    "    save_mode=\"overwrite\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read('top_10_subGNN_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.Experiment(\n",
    "    [tf_idf, bm25],\n",
    "    df,\n",
    "    df2,\n",
    "    eval_metrics=[\"map\", \"recip_rank\"],\n",
    "    names=[\"TF_IDF\", \"BM25\"],\n",
    "    filter_by_topics = True,\n",
    "    filter_by_qrels = True,\n",
    "    save_dir=\"./results\",\n",
    "    save_mode=\"overwrite\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: Could not load an index for ref iter_index_3/data.properties, even though IndexLoader org.terrier.structures.IndexOnDisk$DiskIndexLoader could support that type of index. It may be your ref had a wrong location; Terrier logs may have more information. java.lang.IllegalArgumentException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-77518cb67f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter_index_3/data.properties'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetCollectionStatistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMultipleMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.call_staticmethod\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_utils.pxi\u001b[0m in \u001b[0;36mjnius.check_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mJavaException\u001b[0m: JVM exception occurred: Could not load an index for ref iter_index_3/data.properties, even though IndexLoader org.terrier.structures.IndexOnDisk$DiskIndexLoader could support that type of index. It may be your ref had a wrong location; Terrier logs may have more information. java.lang.IllegalArgumentException"
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of('iter_index_3/data.properties')\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = train.reset_index()[['index',1]].rename(columns={\"index\": \"qid\", 1: \"query\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>why doesn't an optical mouse work on a glass t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the best off-road motorcycle trail ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is Trans Fat? How to reduce that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How many planes Fedex has?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>In the san francisco bay area, does it make se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                              query\n",
       "0    0  why doesn't an optical mouse work on a glass t...\n",
       "1    1       What is the best off-road motorcycle trail ?\n",
       "2    2             What is Trans Fat? How to reduce that?\n",
       "3    3                         How many planes Fedex has?\n",
       "4    4  In the san francisco bay area, does it make se..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_indexer = pt.IterDictIndexer('C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties', blocks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: No Manager implementation found for index C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties\\data.properties (IndexRef) - Do you need to import another package (terrer-core or terrier-rest-client)? Or perhaps the index location is wrong. Found builders were org.terrier.querying.LocalManager$Builder,org.terrier.restclient.RestClientManagerBuilder,org.terrier.querying.ThreadSafeManager$Builder java.lang.IllegalArgumentException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-7ee8a5b04df2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchRetrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_indexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mathematical\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\batchretrieve.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index_location, controls, properties, metadata, num_results, wmodel, threads, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mMF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.terrier.querying.ManagerFactory'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestContextMatching\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"org.terrier.python.RequestContextMatching\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.call_staticmethod\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_utils.pxi\u001b[0m in \u001b[0;36mjnius.check_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mJavaException\u001b[0m: JVM exception occurred: No Manager implementation found for index C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties\\data.properties (IndexRef) - Do you need to import another package (terrer-core or terrier-rest-client)? Or perhaps the index location is wrong. Found builders were org.terrier.querying.LocalManager$Builder,org.terrier.restclient.RestClientManagerBuilder,org.terrier.querying.ThreadSafeManager$Builder java.lang.IllegalArgumentException"
     ]
    }
   ],
   "source": [
    "pt.BatchRetrieve(iter_indexer).search(\"mathematical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "<pyterrier.index._IterDictIndexer_nofifo object at 0x0000018633C52A48>: <class 'pyterrier.index._IterDictIndexer_nofifo'> must be a List[str] or str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-799a1680eaa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindexref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_indexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\index.py\u001b[0m in \u001b[0;36mindex\u001b[1;34m(self, files_path)\u001b[0m\n\u001b[0;32m    827\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckIndexExists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateIndexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[0masList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateAsList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0m_TaggedDocumentSetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\index.py\u001b[0m in \u001b[0;36mcreateAsList\u001b[1;34m(files_path)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0masList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfiles_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{files_path}: {type(files_path)} must be a List[str] or str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0masList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: <pyterrier.index._IterDictIndexer_nofifo object at 0x0000018633C52A48>: <class 'pyterrier.index._IterDictIndexer_nofifo'> must be a List[str] or str"
     ]
    }
   ],
   "source": [
    "indexref = indexer.index(iter_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: No IndexLoaders were supported for indexref C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref? java.lang.UnsupportedOperationException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-719ef1d7256e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMultipleMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.call_staticmethod\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_utils.pxi\u001b[0m in \u001b[0;36mjnius.check_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mJavaException\u001b[0m: JVM exception occurred: No IndexLoaders were supported for indexref C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref? java.lang.UnsupportedOperationException"
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of('C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani index to C:\\Users\\jncwi\\.pyterrier\\corpora\\vaswani\\index\\terrier_stemmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data.direct.bf: 100%|███████████████████████████████████████████████████████████████| 388k/388k [00:00<00:00, 530kiB/s]\n",
      "data.document.fsarrayfile: 100%|████████████████████████████████████████████████████| 234k/234k [00:00<00:00, 332kiB/s]\n",
      "data.inverted.bf: 100%|█████████████████████████████████████████████████████████████| 362k/362k [00:00<00:00, 498kiB/s]\n",
      "data.lexicon.fsomapfile: 100%|██████████████████████████████████████████████████████| 682k/682k [00:01<00:00, 642kiB/s]\n",
      "data.lexicon.fsomaphash: 100%|███████████████████████████████████████████████████████| 777/777 [00:00<00:00, 1.56MiB/s]\n",
      "data.lexicon.fsomapid:  43%|██████████████████████▋                              | 13.0k/30.3k [00:00<00:00, 74.1kiB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a313df2e9126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vaswani\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbm25\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchRetrieve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"terrier_stemmed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"BM25\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\batchretrieve.py\u001b[0m in \u001b[0;36mfrom_dataset\u001b[1;34m(dataset, variant, version, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBatchRetrieve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;31m#: default_controls(dict): stores the default controls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\batchretrieve.py\u001b[0m in \u001b[0;36m_from_dataset\u001b[1;34m(dataset, clz, variant, version, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"latest\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"index versioning not yet supported\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mindexref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mclassname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\datasets.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, variant, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"50pct\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvariant\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mvariant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ex1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m         \u001b[0mthedir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_all_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mthedir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;31m#return pt.autoclass(\"org.terrier.querying.IndexRef\").of(os.path.join(thedir, \"data.properties\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\datasets.py\u001b[0m in \u001b[0;36m_get_all_files\u001b[1;34m(self, component, variant, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                         \u001b[0mRemoteDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not fetch \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\datasets.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(URLs, filename, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m                         \u001b[0munit_divisor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                 ) as bar:\n\u001b[1;32m--> 158\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m                         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                         \u001b[0mbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m                 if (\n\u001b[0;32m    520\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of(indexref)\n",
    "retr = pt.BatchRetrieve(index, controls = {\"wmodel\": \"TF_IDF\"})\n",
    "\n",
    "retr.setControl(\"wmodel\", \"TF_IDF\")\n",
    "retr.setControls({\"wmodel\": \"TF_IDF\"})\n",
    "\n",
    "res=retr.transform(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaException",
     "evalue": "JVM exception occurred: No Manager implementation found for index C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties (IndexRef) - Do you need to import another package (terrer-core or terrier-rest-client)? Or perhaps the index location is wrong. Found builders were org.terrier.querying.LocalManager$Builder,org.terrier.restclient.RestClientManagerBuilder,org.terrier.querying.ThreadSafeManager$Builder java.lang.IllegalArgumentException",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJavaException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-82d7d63d3892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchRetrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"math\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jncwi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyterrier\\batchretrieve.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index_location, controls, properties, metadata, num_results, wmodel, threads, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mMF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.terrier.querying.ManagerFactory'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestContextMatching\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"org.terrier.python.RequestContextMatching\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_export_class.pxi\u001b[0m in \u001b[0;36mjnius.JavaMethod.call_staticmethod\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mjnius\\jnius_utils.pxi\u001b[0m in \u001b[0;36mjnius.check_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mJavaException\u001b[0m: JVM exception occurred: No Manager implementation found for index C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties (IndexRef) - Do you need to import another package (terrer-core or terrier-rest-client)? Or perhaps the index location is wrong. Found builders were org.terrier.querying.LocalManager$Builder,org.terrier.restclient.RestClientManagerBuilder,org.terrier.querying.ThreadSafeManager$Builder java.lang.IllegalArgumentException"
     ]
    }
   ],
   "source": [
    "pt.BatchRetrieve('C:/Users/jncwi/OneDrive/School/CS637/textGCN/iter_index/data.properties').search(\"math\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no metadata\n",
    "# pd_indexer.index(df[\"sentence\"])\n",
    "\n",
    "# Add metadata fields as Pandas.Series objects, with the name of the Series object becoming the name of the meta field.\n",
    "# indexref2 = pd_indexer.index(df[\"sentence\"], df[\"document\"])\n",
    "# pd_indexer.index(df[\"text\"], df[\"docno\"], df[\"url\"])\n",
    "\n",
    "# Add metadata fields as lists to a keyword arguement\n",
    "# pd_indexer.index(df[\"text\"], docno=[\"1\",\"2\",\"3\"], url=[\"url1\", \"url2\", \"url3\"])\n",
    "\n",
    "# Add the metadata fields with a dictionary\n",
    "# meta_fields={\"docno\":[\"1\",\"2\",\"3\"],\"url\":[\"url1\", \"url2\", \"url3\"]}\n",
    "# pd_indexer.index(df[\"text\"], **meta_fields)\n",
    "\n",
    "# Add the entire dataframe as metadata\n",
    "pd_indexer.index(df[\"sentence\"], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
